# Контроль интеграции — AI Personal Chef

## 1. Введение
Цель данного отчёта — зафиксировать текущее состояние интеграции компонентов прототипа, провести end‑to‑end тестирование и определить проблемные зоны для дальнейшей доработки.

---

## 2. End-to-end тестирование прототипа
**Сценарий проверки (MVP):**
1. Пользователь регистрируется и входит в систему.
2. Загружает фото ингредиентов.
3. Backend API принимает запрос и ставит задачу в очередь RabbitMQ.
4. Model Manager получает задачу, вызывает VLM (Ollama) для распознавания ингредиентов.
5. Model Manager передаёт список ингредиентов в LLM (Mistral API) для генерации рецепта.
6. Backend API сохраняет результат в SQLite (история и избранное).
7. Пользователь получает рецепт и видит его в истории/избранном.

**Фактическое состояние:**
- Регистрация и авторизация — реализованы полностью.  
- Backend API — базовые эндпоинты готовы, интеграция с RabbitMQ в процессе.  
- RabbitMQ и Model Manager — структура есть, связка не завершена.  
- VLM (Ollama) — протестирован отдельно, интеграция в пайплайн не завершена.  
- LLM (Mistral API) — вызовы протестированы отдельно, интеграция в пайплайн не завершена.  
- SQLite — подключен, сохранение истории и избранного работает частично.  
- Исключение ингредиентов — реализовано.  
- Уведомления (FCM) — не интегрированы.  
- Frontend/UI — реализованы базовые экраны (регистрация, вход, загрузка фото, история, избранное), но end‑to‑end сценарий не завершён.  

---

## 3. Проверка работы компонентов
- **Backend API ↔ SQLite:** соединение установлено, регистрация/авторизация и сохранение истории работают частично.  
- **Backend API ↔ RabbitMQ:** интеграция в процессе, end‑to‑end цепочка не завершена.  
- **Model Manager ↔ VLM/LLM:** отдельные вызовы работают, но нет связки в общем пайплайне.  
- **История и избранное:** сохраняются частично, требуется доработка.  

---

## 4. Найденные проблемы
- Нет полноценного end‑to‑end сценария (цепочка обрывается на этапе Model Manager).  
- UI реализован частично, нет сквозного тестирования.  
- Нет push‑уведомлений (FCM).  
- Недостаточное покрытие тестами, особенно интеграционными.  
- Ошибки внешних сервисов (VLM/LLM) пока не обрабатываются централизованно.  
- UC8 (Отзывы) остаётся в техническом долге.  

---

## 5. Координация исправлений
- **Backend:** завершить интеграцию API ↔ RabbitMQ ↔ Model Manager.  
- **AI:** объединить вызовы Ollama и Mistral в единый пайплайн.  
- **DevOps:** подготовить docker‑compose для воспроизводимого запуска всех сервисов.  
- **Frontend:** довести UI до полноценного end‑to‑end сценария.  
- **Документация:** обновить README с инструкциями по запуску и тестированию.  

---

## 6. Выводы
- Интеграция компонентов находится на промежуточной стадии.  
- Регистрация, авторизация и исключение ингредиентов реализованы полностью.  
- История и избранное сохраняются частично, но end‑to‑end сценарий пока не завершён.  
- Основные задачи на ближайший спринт: довести связку Backend ↔ RabbitMQ ↔ Model Manager ↔ VLM/LLM, завершить сохранение истории/избранного и интегрировать UI в сквозной сценарий.
