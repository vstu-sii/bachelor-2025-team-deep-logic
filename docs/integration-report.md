# Контроль интеграции — AI Personal Chef

## 1. Введение
Цель данного отчёта — зафиксировать текущее состояние интеграции компонентов прототипа, провести end‑to‑end тестирование и определить проблемные зоны для дальнейшей доработки.

---

## 2. End-to-end тестирование прототипа
**Сценарий проверки (MVP):**
1. Пользователь загружает фото ингредиентов.
2. Backend API принимает запрос и ставит задачу в очередь RabbitMQ.
3. Model Manager получает задачу, вызывает VLM (Ollama) для распознавания ингредиентов.
4. Model Manager передаёт список ингредиентов в LLM (Mistral API) для генерации рецепта.
5. Результат возвращается в Backend API и сохраняется в PostgreSQL.
6. Пользователь получает рецепт и видит его в истории.

**Фактическое состояние:**
- Backend API — в разработке, базовые эндпоинты частично готовы.  
- RabbitMQ и Model Manager — структура есть, интеграция в процессе.  
- VLM (Ollama) — протестирован отдельно, интеграция в пайплайн не завершена.  
- LLM (Mistral API) — вызовы протестированы отдельно, интеграция в пайплайн не завершена.  
- PostgreSQL — схема данных определена, подключение проверено.  
- Уведомления (FCM) — не интегрированы.  
- Frontend/UI — отсутствует, тестирование ведётся через API.  

---

## 3. Проверка работы компонентов
- **Backend API ↔ PostgreSQL:** соединение установлено, базовые операции работают.  
- **Backend API ↔ RabbitMQ:** интеграция в процессе, end‑to‑end цепочка не завершена.  
- **Model Manager ↔ VLM/LLM:** отдельные вызовы работают, но нет связки в общем пайплайне.  
- **История запросов:** сохраняется частично, требуется доработка.  

---

## 4. Найденные проблемы
- Нет полноценного end‑to‑end сценария (цепочка обрывается на этапе Model Manager).  
- Отсутствует UI, что усложняет пользовательское тестирование.  
- Нет push‑уведомлений (FCM).  
- Недостаточное покрытие тестами, особенно интеграционными.  
- Ошибки внешних сервисов (VLM/LLM) пока не обрабатываются централизованно.  

---

## 5. Координация исправлений
- **Backend команда:** завершить интеграцию API ↔ RabbitMQ ↔ Model Manager.  
- **AI команда:** объединить вызовы Ollama и Mistral в единый пайплайн.  
- **DevOps:** подготовить docker‑compose для воспроизводимого запуска всех сервисов.  
- **Документация:** обновить README с инструкциями по запуску и тестированию.  

---

## 6. Выводы
- Интеграция компонентов находится на промежуточной стадии.  
- Отдельные части системы работают, но end‑to‑end сценарий пока не завершён.  
- Основные задачи на ближайший спринт: довести связку Backend ↔ RabbitMQ ↔ Model Manager ↔ VLM/LLM и обеспечить сохранение истории в БД.  
